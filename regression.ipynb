{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score   # CHANGED FOR REGRESSION\nfrom sklearn.ensemble import RandomForestRegressor                              # CHANGED FOR REGRESSION\nfrom sklearn.neighbors import KNeighborsRegressor                               # CHANGED FOR REGRESSION\nimport joblib\n\n# Load Data\ndf = pd.read_csv(\"healthcare_dataset.csv\")\n\n# ---------------------------------------------------\n# IDENTIFY NUMERIC & CATEGORICAL COLUMNS\n# ---------------------------------------------------\n\nnum_cols = df.select_dtypes(include=np.number).columns.tolist()\nif \"disease_risk\" in num_cols:\n    num_cols.remove(\"disease_risk\")  # we don't want to treat target as input\n\ncat_cols = df.select_dtypes(include=\"object\").columns.tolist()\n\n# ---------------------------------------------------\n# BOX PLOTS BEFORE IMPUTATION\n# ---------------------------------------------------\n\nprint(\"\\nBoxplots for numeric columns (BEFORE imputation).\")\nplt.figure(figsize=(10, len(num_cols) * 2.2))\nfor i, col in enumerate(num_cols, 1):\n    plt.subplot(len(num_cols), 1, i)\n    plt.boxplot(df[col].dropna(), vert=False)\n    plt.title(f\"Boxplot - {col} (before imputation)\")\nplt.tight_layout()\nplt.show()\n\n# ---------------------------------------------------\n# HANDLE MISSING VALUES\n# ---------------------------------------------------\n\n# Numeric → median\ndf[num_cols] = df[num_cols].fillna(df[num_cols].median())\n\n# Categorical → mode\nfor col in cat_cols:\n    mode_val = df[col].mode()\n    if len(mode_val) > 0:\n        df[col] = df[col].fillna(mode_val.iloc[0])  # CHANGED: avoid IndexError\n    else:\n        df[col] = df[col].fillna(\"Unknown\")\n\n# ---------------------------------------------------\n# OUTLIER REMOVAL (IQR METHOD)\n# ---------------------------------------------------\n\nfor col in num_cols:\n    Q1 = df[col].quantile(0.25)\n    Q3 = df[col].quantile(0.75)\n    IQR = Q3 - Q1\n    low = Q1 - 1.5 * IQR\n    high = Q3 + 1.5 * IQR\n    df = df[(df[col] >= low) & (df[col] <= high)]\n\n# ---------------------------------------------------\n# BOX PLOTS AFTER IMPUTATION & OUTLIER REMOVAL\n# ---------------------------------------------------\n\nprint(\"\\nBoxplots for numeric columns (AFTER cleaning).\")\nplt.figure(figsize=(10, len(num_cols) * 2.2))\nfor i, col in enumerate(num_cols, 1):\n    plt.subplot(len(num_cols), 1, i)\n    plt.boxplot(df[col], vert=False)\n    plt.title(f\"Boxplot - {col} (after cleaning)\")\nplt.tight_layout()\nplt.show()\n\n# ---------------------------------------------------\n# ENCODE CATEGORICAL DATA\n# ---------------------------------------------------\n\ndf = pd.get_dummies(df, columns=cat_cols, drop_first=True)  # CHANGED: works same for regression\n\n# ---------------------------------------------------\n# SPLIT DATA\n# ---------------------------------------------------\n\nX = df.drop(\"disease_risk\", axis=1)\ny = df[\"disease_risk\"]  # CHANGED FOR REGRESSION (now continuous target)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# ---------------------------------------------------\n# SCALE DATA\n# ---------------------------------------------------\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# ---------------------------------------------------\n# MODEL 1: RANDOM FOREST REGRESSOR\n# ---------------------------------------------------\n\nrf = RandomForestRegressor(random_state=42)  # CHANGED FOR REGRESSION\nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\n\n# REGRESSION METRICS — CHANGED\nprint(\"\\nRandomForestRegressor Performance:\")\nprint(\"MSE:\", mean_squared_error(y_test, rf_pred))\nprint(\"MAE:\", mean_absolute_error(y_test, rf_pred))\nprint(\"R2 Score:\", r2_score(y_test, rf_pred))\n\n# ---------------------------------------------------\n# MODEL 2: KNN REGRESSOR\n# ---------------------------------------------------\n\nknn = KNeighborsRegressor(n_neighbors=5)  # CHANGED FOR REGRESSION\nknn.fit(X_train, y_train)\nknn_pred = knn.predict(X_test)\n\nprint(\"\\nKNeighborsRegressor Performance:\")\nprint(\"MSE:\", mean_squared_error(y_test, knn_pred))\nprint(\"MAE:\", mean_absolute_error(y_test, knn_pred))\nprint(\"R2 Score:\", r2_score(y_test, knn_pred))\n\n# ---------------------------------------------------\n# SAVE BEST MODEL\n# ---------------------------------------------------\n\nbest_model = rf if r2_score(y_test, rf_pred) > r2_score(y_test, knn_pred) else knn\njoblib.dump(best_model, \"best_regression_model.pkl\")  # CHANGED (model name)\n\nprint(\"\\nModel saved as best_regression_model.pkl\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}